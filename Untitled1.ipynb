{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d55e4eb3-3f2a-4772-94f5-48e8ecb65b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples loaded: 6259\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "Python int too large to convert to C long",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 102\u001b[0m\n\u001b[0;32m     96\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     97\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     98\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     99\u001b[0m ]\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Plot training history\u001b[39;00m\n\u001b[0;32m    111\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py:2079\u001b[0m, in \u001b[0;36msignbit\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2074\u001b[0m     x \u001b[38;5;241m=\u001b[39m cast(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mless(\n\u001b[0;32m   2076\u001b[0m         tf\u001b[38;5;241m.\u001b[39mbitwise\u001b[38;5;241m.\u001b[39mbitwise_and(\n\u001b[0;32m   2077\u001b[0m             tf\u001b[38;5;241m.\u001b[39mbitcast(x, tf\u001b[38;5;241m.\u001b[39mint32),\n\u001b[0;32m   2078\u001b[0m             \u001b[38;5;66;03m# tf.float32 sign bit\u001b[39;00m\n\u001b[1;32m-> 2079\u001b[0m             \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0x80000000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2080\u001b[0m         ),\n\u001b[0;32m   2081\u001b[0m         \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2082\u001b[0m     )\n",
      "\u001b[1;31mOverflowError\u001b[0m: Python int too large to convert to C long"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# Configuration\n",
    "img_size = 224\n",
    "DataDirectory = \"./train/\"\n",
    "classes = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "LIMIT_PER_CLASS = 1000  # Set to None to use all images\n",
    "\n",
    "# Load and preprocess data\n",
    "def create_training_data():\n",
    "    training_data = []\n",
    "    \n",
    "    for category in classes:\n",
    "        path = os.path.join(DataDirectory, category)\n",
    "        class_num = classes.index(category)\n",
    "        images_loaded = 0\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_path = os.path.join(path, img)\n",
    "                img_array = cv2.imread(img_path)\n",
    "                if img_array is None:\n",
    "                    continue\n",
    "                    \n",
    "                new_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                training_data.append([new_array, class_num])\n",
    "                \n",
    "                images_loaded += 1\n",
    "                if LIMIT_PER_CLASS and images_loaded >= LIMIT_PER_CLASS:\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "# Create dataset\n",
    "training_data = create_training_data()\n",
    "print(f\"Total samples loaded: {len(training_data)}\")\n",
    "\n",
    "# Shuffle and split data\n",
    "random.shuffle(training_data)\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "\n",
    "X = np.array(X).astype('float32') / 255.0\n",
    "Y = np.array(Y).astype('int32')\n",
    "\n",
    "# Split into train and validation\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create model\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(img_size, img_size, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build new model\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "predictions = layers.Dense(7, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Add callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_loss'),\n",
    "    tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d1b4f2-79a2-4a04-8029-c33a93b1350b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
